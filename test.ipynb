{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.code.notebook.error": {
       "message": "No module named 'tensorflow'",
       "name": "ModuleNotFoundError",
       "stack": "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)\n\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21284\\1945103609.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAdadelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\n\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
      }
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "# Data visualization\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import numpy as np\r\n",
    "import pandas as pd \r\n",
    "import os\r\n",
    "# Keras\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers\r\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, RMSprop\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense, Dropout\r\n",
    "import keras.backend as K\r\n",
    "# Train-Test\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "# Scaling data\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "# Classification Report\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from keras.layers import Dense,Dropout,Flatten\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "from keras.utils.np_utils import to_categorical\r\n",
    "\r\n",
    "PATH = os.getcwd()\r\n",
    "PATH_condition = PATH+\"/data/condition\"\r\n",
    "PATH_control = PATH+\"/data/control\"\r\n",
    "PATH_scores = PATH+\"/data/scores\"\r\n",
    "\r\n",
    "df = pd.read_csv(PATH_scores+\"/scores.csv\",encoding= 'unicode_escape')\r\n",
    "df = df.fillna(0)\r\n",
    "# print(\"df\",df)\r\n",
    "# print(\"PATH \",PATH_scores)\r\n",
    "# dftrain = pd.read_csv(PATH_scores+\"/scores.csv\",encoding= 'unicode_escape')\r\n",
    "# # dftrain = pd.read_csv('coords_500_train_for_validate.csv')\r\n",
    "# dftest = pd.read_csv(PATH_scores+\"/scores.csv\",encoding= 'unicode_escape')\r\n",
    "# # dfvalidate = pd.read_csv('coords_500_validate.csv')\r\n",
    "\r\n",
    "# dftrain_s = dftrain.sample(frac=1, random_state=1234)\r\n",
    "# dftest_s = dftest.sample(frac=1, random_state=1234)\r\n",
    "# # dfvalidate_s = dfvalidate.sample(frac=1, random_state=1234)\r\n",
    "\r\n",
    "# # normal\r\n",
    "Y=df[['solution']]\r\n",
    "# print(\"Label\",Y)\r\n",
    "X= df.drop(['name','solution','ages','edu',], axis=1) # features\r\n",
    "# print(\"Train\",X)\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\r\n",
    "print(\"Train\",X_train)\r\n",
    "print(\"label_train\",y_train)\r\n",
    "print(\"Test\",X_test)\r\n",
    "print(\"label_test\",y_test)\r\n",
    "# y_train = dftrain_s['solution'] # target value\r\n",
    "# X_test = dftest_s.drop(['name','solution'], axis=1) # features\r\n",
    "# y_test = dftest_s['solution']\r\n",
    "# # X_validate = dfvalidate.drop(['name', 'class'], axis=1)\r\n",
    "# # y_validate = dfvalidate_s['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "vec = label_encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(vec, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Y\",Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yec = label_encoder.fit_transform(y_test)\n",
    "Ytest = to_categorical(yec, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"vec\",vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"yec\",yec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1250, input_dim = X_train.shape[1], activation = 'relu')) # input layer requires input_dim param\n",
    "model.add(Dense(1100, activation = 'relu'))\n",
    "model.add(Dense(1000, activation = 'relu'))\n",
    "model.add(Dense(900, activation = 'relu'))\n",
    "model.add(Dense(750, activation = 'relu'))\n",
    "model.add(Dense(600, activation = 'relu'))\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.00008)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train, Y, validation_split=0.33, epochs = 200, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1250, input_dim = X_train.shape[1], activation = 'relu')) # input layer requires input_dim param\n",
    "model.add(Dense(1100, activation = 'relu'))\n",
    "model.add(Dense(1000, activation = 'relu'))\n",
    "model.add(Dense(900, activation = 'relu'))\n",
    "model.add(Dense(750, activation = 'relu'))\n",
    "model.add(Dense(600, activation = 'relu'))\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "opt = keras.optimizers.Adam(learning_rate=0.00008)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y, validation_split=0.1, epochs = 10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_train, Y, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validate'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = model.predict(X_test)\n",
    "pred_x = np.argmax(y_pred_class, axis=1)\n",
    "y_test_class = np.argmax(Ytest, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "classlist = ['depression','non-depression']\n",
    "P_classlist = ['depression','non-depression']\n",
    "cm = confusion_matrix(y_test_class, pred_x)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, classlist, P_classlist) #(cm, range(8), range(8))\n",
    "sns.set(font_scale=1.4) # for label size\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_class, pred_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "target = ['depression','non-depression']\n",
    "# set plot figure size\n",
    "fig, c_ax = plt.subplots(1,1, figsize = (12, 8))\n",
    "\n",
    "# function for scoring roc auc score for multi-class\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "\n",
    "    for (idx, c_label) in enumerate(target):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n",
    "        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "    c_ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "\n",
    "print('ROC AUC score:', multiclass_roc_auc_score(y_test_class, pred_x))\n",
    "\n",
    "c_ax.legend()\n",
    "c_ax.set_xlabel('False Positive Rate')\n",
    "c_ax.set_ylabel('True Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "490a93732027bfa3348d3d672a8d840585c8dfe74407ba20850eabfc16721a89"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 32-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}